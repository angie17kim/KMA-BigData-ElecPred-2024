{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 노트북 3/5: 변수 정규화\n",
    "사용법: \n",
    "- 전처리 노트북 2를 실행 후 01_electric_train_features.csv, 01_electric_test_features.csv 를 asset_path에 저장 \n",
    "- 만약 data_path가 없는 경로라면 생성해주세요\n",
    "- 각 셀을 순서대로 실행\n",
    "\n",
    "결과물:\n",
    "- 02_train_input_transformed.csv\n",
    "- 02_train_elec_transformed.csv\n",
    "- 02_train_meta_transformed.csv\n",
    "- 02_test_input_transformed.csv\n",
    "- 02_test_meta_transformed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Data handling and preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Parallel processing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# YAML file handling\n",
    "import yaml\n",
    "\n",
    "from preprocessing_utils import Backup, get_data_paths\n",
    "asset_path, data_path = get_data_paths()\n",
    "\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv((Path(asset_path, '01_electric_train_features.csv')))\n",
    "test_data  = pd.read_csv((Path(asset_path, '01_electric_test_features.csv')))\n",
    "\n",
    "train_data['datetime'] = pd.to_datetime(train_data['datetime'])\n",
    "test_data['datetime'] = pd.to_datetime(test_data['datetime'])\n",
    "\n",
    "pre_num_train      = train_data['num'].values\n",
    "pre_datetime_train = train_data['datetime'].values\n",
    "\n",
    "pre_num_test      = test_data['num'].values\n",
    "pre_datetime_test = test_data['datetime'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['is_dummy', 'num', 'lat', 'lon', 'district', 'units', 'year',\n",
      "       'datetime', 'holiday', 'altitude', 'temp', 'humid', 'wind', 'rain',\n",
      "       'tchi', 'dci', 'hi', 'wchi', 'atemp', 'sum_qctr', 'sum_load',\n",
      "       'avg_load', 'n_mean_load', 'elec'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_dummy</th>\n",
       "      <th>num</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>district</th>\n",
       "      <th>units</th>\n",
       "      <th>year</th>\n",
       "      <th>datetime</th>\n",
       "      <th>holiday</th>\n",
       "      <th>altitude</th>\n",
       "      <th>...</th>\n",
       "      <th>tchi</th>\n",
       "      <th>dci</th>\n",
       "      <th>hi</th>\n",
       "      <th>wchi</th>\n",
       "      <th>atemp</th>\n",
       "      <th>sum_qctr</th>\n",
       "      <th>sum_load</th>\n",
       "      <th>avg_load</th>\n",
       "      <th>n_mean_load</th>\n",
       "      <th>elec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>33.273132</td>\n",
       "      <td>126.544771</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>18.254837</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>40.481506</td>\n",
       "      <td>63.479224</td>\n",
       "      <td>681.185362</td>\n",
       "      <td>-1.580046</td>\n",
       "      <td>6950</td>\n",
       "      <td>751.32</td>\n",
       "      <td>68.301818</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>99.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>33.273132</td>\n",
       "      <td>126.544771</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>26.118528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>40.576487</td>\n",
       "      <td>63.122127</td>\n",
       "      <td>702.765266</td>\n",
       "      <td>-1.669947</td>\n",
       "      <td>6950</td>\n",
       "      <td>692.60</td>\n",
       "      <td>62.963636</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>91.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>33.273132</td>\n",
       "      <td>126.544771</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>31.523261</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>40.517872</td>\n",
       "      <td>63.428060</td>\n",
       "      <td>733.390760</td>\n",
       "      <td>-2.077127</td>\n",
       "      <td>6950</td>\n",
       "      <td>597.48</td>\n",
       "      <td>54.316364</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>79.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>33.273132</td>\n",
       "      <td>126.544771</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>33.736168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>39.665205</td>\n",
       "      <td>65.751762</td>\n",
       "      <td>683.542071</td>\n",
       "      <td>-2.043783</td>\n",
       "      <td>6950</td>\n",
       "      <td>553.48</td>\n",
       "      <td>50.316364</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>73.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>33.273132</td>\n",
       "      <td>126.544771</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>32.382356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>39.728290</td>\n",
       "      <td>65.665011</td>\n",
       "      <td>674.487163</td>\n",
       "      <td>-1.985171</td>\n",
       "      <td>6950</td>\n",
       "      <td>526.24</td>\n",
       "      <td>47.840000</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>69.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_dummy   num        lat         lon  district  units  year  \\\n",
       "0         0  4821  33.273132  126.544771         3     11  2021   \n",
       "1         0  4821  33.273132  126.544771         3     11  2021   \n",
       "2         0  4821  33.273132  126.544771         3     11  2021   \n",
       "3         0  4821  33.273132  126.544771         3     11  2021   \n",
       "4         0  4821  33.273132  126.544771         3     11  2021   \n",
       "\n",
       "             datetime  holiday   altitude  ...  tchi        dci         hi  \\\n",
       "0 2021-01-01 00:00:00        1  18.254837  ...  -1.0  40.481506  63.479224   \n",
       "1 2021-01-01 01:00:00        1  26.118528  ...  -0.6  40.576487  63.122127   \n",
       "2 2021-01-01 02:00:00        1  31.523261  ...  -1.3  40.517872  63.428060   \n",
       "3 2021-01-01 03:00:00        1  33.736168  ...  -0.2  39.665205  65.751762   \n",
       "4 2021-01-01 04:00:00        1  32.382356  ...  -0.8  39.728290  65.665011   \n",
       "\n",
       "         wchi     atemp  sum_qctr  sum_load   avg_load  n_mean_load   elec  \n",
       "0  681.185362 -1.580046      6950    751.32  68.301818    68.606449  99.56  \n",
       "1  702.765266 -1.669947      6950    692.60  62.963636    68.606449  91.78  \n",
       "2  733.390760 -2.077127      6950    597.48  54.316364    68.606449  79.17  \n",
       "3  683.542071 -2.043783      6950    553.48  50.316364    68.606449  73.34  \n",
       "4  674.487163 -1.985171      6950    526.24  47.840000    68.606449  69.73  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['is_dummy', 'num', 'lat', 'lon', 'district', 'units', 'year',\n",
      "       'datetime', 'holiday', 'altitude', 'temp', 'humid', 'wind', 'rain',\n",
      "       'tchi', 'dci', 'hi', 'wchi', 'atemp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_dummy</th>\n",
       "      <th>num</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>district</th>\n",
       "      <th>units</th>\n",
       "      <th>year</th>\n",
       "      <th>datetime</th>\n",
       "      <th>holiday</th>\n",
       "      <th>altitude</th>\n",
       "      <th>temp</th>\n",
       "      <th>humid</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>tchi</th>\n",
       "      <th>dci</th>\n",
       "      <th>hi</th>\n",
       "      <th>wchi</th>\n",
       "      <th>atemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4816</td>\n",
       "      <td>33.274294</td>\n",
       "      <td>126.272389</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>18.097368</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>40.957620</td>\n",
       "      <td>60.453669</td>\n",
       "      <td>738.881591</td>\n",
       "      <td>-1.316025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4816</td>\n",
       "      <td>33.274294</td>\n",
       "      <td>126.272389</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>25.985794</td>\n",
       "      <td>3.1</td>\n",
       "      <td>69.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>41.016686</td>\n",
       "      <td>59.985268</td>\n",
       "      <td>724.527134</td>\n",
       "      <td>-1.043713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4816</td>\n",
       "      <td>33.274294</td>\n",
       "      <td>126.272389</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>31.427094</td>\n",
       "      <td>3.6</td>\n",
       "      <td>68.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>41.883312</td>\n",
       "      <td>57.956953</td>\n",
       "      <td>686.953076</td>\n",
       "      <td>-0.229598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4816</td>\n",
       "      <td>33.274294</td>\n",
       "      <td>126.272389</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>33.687383</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>42.384720</td>\n",
       "      <td>56.264272</td>\n",
       "      <td>725.197689</td>\n",
       "      <td>-0.314628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4816</td>\n",
       "      <td>33.274294</td>\n",
       "      <td>126.272389</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>32.384968</td>\n",
       "      <td>4.2</td>\n",
       "      <td>69.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.653310</td>\n",
       "      <td>55.431667</td>\n",
       "      <td>685.767983</td>\n",
       "      <td>0.339766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_dummy   num        lat         lon  district  units  year  \\\n",
       "0         0  4816  33.274294  126.272389         3     11  2023   \n",
       "1         0  4816  33.274294  126.272389         3     11  2023   \n",
       "2         0  4816  33.274294  126.272389         3     11  2023   \n",
       "3         0  4816  33.274294  126.272389         3     11  2023   \n",
       "4         0  4816  33.274294  126.272389         3     11  2023   \n",
       "\n",
       "             datetime  holiday   altitude  temp  humid  wind  rain  tchi  \\\n",
       "0 2023-01-01 00:00:00        1  18.097368   3.0   68.6   2.9   0.0  -0.1   \n",
       "1 2023-01-01 01:00:00        1  25.985794   3.1   69.4   2.7   0.0   0.3   \n",
       "2 2023-01-01 02:00:00        1  31.427094   3.6   68.3   2.3   0.0   1.2   \n",
       "3 2023-01-01 03:00:00        1  33.687383   4.0   69.2   3.1   0.0   1.1   \n",
       "4 2023-01-01 04:00:00        1  32.384968   4.2   69.5   2.5   0.0   2.0   \n",
       "\n",
       "         dci         hi        wchi     atemp  \n",
       "0  40.957620  60.453669  738.881591 -1.316025  \n",
       "1  41.016686  59.985268  724.527134 -1.043713  \n",
       "2  41.883312  57.956953  686.953076 -0.229598  \n",
       "3  42.384720  56.264272  725.197689 -0.314628  \n",
       "4  42.653310  55.431667  685.767983  0.339766  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.columns)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec_variables = ['sum_qctr', 'sum_load', 'avg_load','n_mean_load', 'elec']\n",
    "\n",
    "standard_transformed = ['temp', 'humid', 'tchi', 'dci', 'hi', 'wchi', 'atemp']\n",
    "to_quantile_transformed = ['rain', 'units', 'sum_qctr', 'sum_load', 'avg_load','n_mean_load', 'elec']\n",
    "min_max_transformed = ['lon', 'lat', 'wind', 'altitude']\n",
    "categorical_to_onehot = [('district',[0,1,2,3])]\n",
    "no_transform = ['is_dummy', 'num', 'year','datetime', 'holiday'] + elec_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['district_c0', 'district_c1', 'district_c2', 'district_c3', 'units_qt', 'lon_mm', 'lat_mm', 'holiday', 'altitude_mm', 'temp_st', 'humid_st', 'tchi_st', 'dci_st', 'hi_st', 'wchi_st', 'atemp_st', 'rain_qt', 'wind_mm']\n",
    "elec_cols  = ['sum_qctr_qt', 'sum_load_qt', 'avg_load_qt', 'n_mean_load_qt', 'elec_qt', 'sum_qctr', 'sum_load', 'avg_load', 'n_mean_load', 'elec']\n",
    "meta_cols  = ['is_dummy', 'num', 'year', 'datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Transforms on Train Data (Calculate Statistics etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {}\n",
    "\n",
    "train_value_dict = {}\n",
    "\n",
    "for tag, cols in zip(['_st', '_qt', '_mm'], [standard_transformed, to_quantile_transformed, min_max_transformed]):\n",
    "    for col in cols:\n",
    "\n",
    "        col_values = train_data[[col]].values\n",
    "\n",
    "        if col in standard_transformed:\n",
    "            qt = StandardScaler()\n",
    "        elif col in to_quantile_transformed:\n",
    "            qt = QuantileTransformer(output_distribution='uniform')\n",
    "        elif col in min_max_transformed:\n",
    "            qt = MinMaxScaler()\n",
    "        else:\n",
    "            print('error')\n",
    "            break\n",
    "            \n",
    "        col_transformed = qt.fit_transform(col_values)\n",
    "        transforms[col] = qt\n",
    "\n",
    "        train_value_dict[col + tag] = col_transformed.ravel()\n",
    "\n",
    "        if col in elec_variables:\n",
    "            with open(Path(data_path,f'{col}_transform.pkl'), 'wb') as f:\n",
    "                pickle.dump(transforms[col], f)\n",
    "\n",
    "for col, cat in categorical_to_onehot:\n",
    "    col_values = train_data[col].values\n",
    "    qt = OneHotEncoder(categories=[cat])\n",
    "    col_transformed = qt.fit_transform(col_values.reshape(-1,1)).toarray()\n",
    "    transforms[col] = qt\n",
    "    for i in range(col_transformed.shape[1]):\n",
    "        train_value_dict[col + f'_c{i}'] = col_transformed[:,i].ravel()\n",
    "\n",
    "for col in no_transform:\n",
    "    train_value_dict[col] = train_data[col].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['temp_st', 'humid_st', 'tchi_st', 'dci_st', 'hi_st', 'wchi_st', 'atemp_st', 'rain_qt', 'units_qt', 'sum_qctr_qt', 'sum_load_qt', 'avg_load_qt', 'n_mean_load_qt', 'elec_qt', 'lon_mm', 'lat_mm', 'wind_mm', 'altitude_mm', 'district_c0', 'district_c1', 'district_c2', 'district_c3', 'is_dummy', 'num', 'year', 'datetime', 'holiday', 'sum_qctr', 'sum_load', 'avg_load', 'n_mean_load', 'elec'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_value_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(input_cols + elec_cols + meta_cols) == set(train_value_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Transforms on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value_dict = {}\n",
    "\n",
    "for tag, cols in zip(['_st', '_qt', '_mm'], [standard_transformed, to_quantile_transformed, min_max_transformed]):\n",
    "    for col in cols:\n",
    "        if col in elec_variables: continue\n",
    "        \n",
    "        col_values = test_data[[col]].values\n",
    "\n",
    "        qt = transforms[col]\n",
    "        col_transformed = qt.transform(col_values)\n",
    "\n",
    "        test_value_dict[col + tag] = col_transformed.ravel()\n",
    "\n",
    "        if col in min_max_transformed:\n",
    "            # trim the values to 0~1\n",
    "            test_value_dict[col + tag] = np.clip(test_value_dict[col + tag], 0, 1).ravel()\n",
    "\n",
    "for col, cat in categorical_to_onehot:\n",
    "    \n",
    "    qt = transforms[col]\n",
    "    col_values = test_data[col].values\n",
    "    col_transformed = qt.transform(col_values.reshape(-1,1)).toarray()\n",
    "    for i in range(col_transformed.shape[1]):\n",
    "        test_value_dict[col + f'_c{i}'] = col_transformed[:,i].ravel()\n",
    "\n",
    "for col in no_transform:\n",
    "    if col in elec_variables: continue\n",
    "    test_value_dict[col] = test_data[col].values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(input_cols + meta_cols) == set(test_value_dict.keys()), print(set(input_cols + meta_cols) - set(test_value_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_whole_df = pd.DataFrame(train_value_dict)\n",
    "test_whole_df = pd.DataFrame(test_value_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_df = train_whole_df[input_cols]\n",
    "train_elec_df = train_whole_df[elec_cols]\n",
    "train_meta_df = train_whole_df[meta_cols]\n",
    "\n",
    "test_input_df = test_whole_df[input_cols]\n",
    "test_meta_df = test_whole_df[meta_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_df.to_csv(Path(asset_path, '02_train_input_transformed.csv'), index=False)\n",
    "train_elec_df.to_csv(Path(asset_path, '02_train_elec_transformed.csv'), index=False)\n",
    "train_meta_df.to_csv(Path(asset_path, '02_train_meta_transformed.csv'), index=False)\n",
    "\n",
    "test_input_df.to_csv(Path(asset_path, '02_test_input_transformed.csv'), index=False)\n",
    "test_meta_df.to_csv(Path(asset_path, '02_test_meta_transformed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
