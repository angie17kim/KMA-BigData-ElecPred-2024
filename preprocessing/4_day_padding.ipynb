{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 노트북 4/5: Day Padding\n",
    "설명:\n",
    "- 본 전처리에서는 편의성을 위하여 연도마다 데이터가 독립적으로 구분되도록 yeartag를 지정하는 중임\n",
    "- 시간 지연 변수를 추가할때 1월 1일에서 과거 연도의 데이터를 참조하지 않도록 하기 위해 실제 모델 학습에는 사용되지 않지만 같은 yeartag를 가지는 dummy 데이터를 생성함\n",
    "- 1월 1일에서 과거의 정보가 없는 경우 (2020년, 그리고 중간 연도의 데이터가 존재하지 않는 격자인경우), 1월 1일의 정보를 그대로 복사하여 작년 12월 31일 정보로 추가\n",
    "\n",
    "사용법: \n",
    "- 전처리 노트북 3를 실행 후 결과물들을 asset_path에 저장 \n",
    "- 각 opt에 대하여 셀을 순서대로 실행\n",
    "\n",
    "결과물:\n",
    "- 03_train_input_padding.csv\n",
    "- 03_train_elec_padding.csv\n",
    "- 03_train_meta_padding.csv\n",
    "- 03_test_input_padding.csv\n",
    "- 03_test_meta_padding.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocessing_utils import Backup, get_data_paths\n",
    "asset_path, data_path = get_data_paths()\n",
    "\n",
    "SAVE_TO_DATA = False\n",
    "\n",
    "PAD_HOUR = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily pad is allowed because we copy the first values of the day.\n",
    "assert PAD_HOUR % 24 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['district_c0', 'district_c1', 'district_c2', 'district_c3', 'units_qt', 'lon_mm', 'lat_mm', 'holiday', 'altitude_mm', 'temp_st', 'humid_st', 'tchi_st', 'dci_st', 'hi_st', 'wchi_st', 'atemp_st', 'rain_qt', 'wind_mm']\n",
    "elec_cols  = ['sum_qctr_qt', 'sum_load_qt', 'avg_load_qt', 'n_mean_load_qt', 'elec_qt', 'sum_qctr', 'sum_load', 'avg_load', 'n_mean_load', 'elec']\n",
    "meta_cols  = ['is_dummy', 'num', 'year', 'datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "train_input_df = pd.read_csv(Path(asset_path, '02_train_input_transformed.csv'))\n",
    "train_elec_df = pd.read_csv(Path(asset_path, '02_train_elec_transformed.csv'))\n",
    "train_meta_df = pd.read_csv(Path(asset_path, '02_train_meta_transformed.csv'))\n",
    "\n",
    "test_input_df = pd.read_csv(Path(asset_path, '02_test_input_transformed.csv'))\n",
    "test_meta_df = pd.read_csv(Path(asset_path, '02_test_meta_transformed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ['train', 'test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt == 'train':\n",
    "    total_df = pd.concat([train_input_df, train_elec_df, train_meta_df], axis=1)\n",
    "    total_df['datetime'] = pd.to_datetime(total_df['datetime'])\n",
    "\n",
    "else:\n",
    "    total_df = pd.concat([test_input_df, test_meta_df], axis=1)\n",
    "    total_df['datetime'] = pd.to_datetime(total_df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_num = total_df['num'].values\n",
    "pre_datetime = total_df['datetime'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Backup.save_with_key(total_df, f'backup1_{opt}')\n",
    "\n",
    "get_backup = False\n",
    "if get_backup:\n",
    "    total_df = Backup.copy_data_with_key(f'backup1_{opt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 866/866 [34:01<00:00,  2.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "# 기존 그룹화\n",
    "grouped = total_df.groupby(['num', 'year'])\n",
    "\n",
    "# 결과를 저장할 딕셔너리\n",
    "result_dict = {}\n",
    "\n",
    "# 그룹을 처리하는 함수 정의\n",
    "def process_group(name_group):\n",
    "    name, group = name_group\n",
    "    num, year = name\n",
    "\n",
    "    group['padding_dummy'] = 0\n",
    "    \n",
    "    first_datetime = group['datetime'].iloc[0]\n",
    "    \n",
    "    # 첫 datetime 이전 24시간 생성\n",
    "    new_datetimes = pd.date_range(end=first_datetime, periods=PAD_HOUR+1, freq='h')[:-1]\n",
    "    \n",
    "    flag = False\n",
    "    new_rows = []\n",
    "    for idx, dts in enumerate(new_datetimes):\n",
    "        search = total_df[(total_df['num'] == num) & (total_df['datetime'] == dts)]\n",
    "        if search.shape[0] > 0:\n",
    "            if search.shape[0] > 1:\n",
    "                print('error')\n",
    "            search = search.iloc[0].copy()\n",
    "            search['padding_dummy'] = 1\n",
    "            search['yeartag'] = year\n",
    "            new_rows.append(search)\n",
    "        else:\n",
    "            new_row = group.iloc[idx].copy()\n",
    "            new_row['datetime'] = dts\n",
    "            new_row['padding_dummy'] = 1\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    new_rows = pd.concat(new_rows, axis=1).T\n",
    "    \n",
    "    group = pd.concat([new_rows, group]).sort_values(by='datetime').reset_index(drop=True)\n",
    "    return name, group\n",
    "\n",
    "# 병렬 처리\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    futures = {executor.submit(process_group, item): item for item in grouped}\n",
    "    \n",
    "    for future in tqdm(as_completed(futures), total=len(grouped)):\n",
    "        name, group = future.result()\n",
    "        result_dict[name] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_c0</th>\n",
       "      <th>district_c1</th>\n",
       "      <th>district_c2</th>\n",
       "      <th>district_c3</th>\n",
       "      <th>units_qt</th>\n",
       "      <th>lon_mm</th>\n",
       "      <th>lat_mm</th>\n",
       "      <th>holiday</th>\n",
       "      <th>altitude_mm</th>\n",
       "      <th>temp_st</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_load</th>\n",
       "      <th>avg_load</th>\n",
       "      <th>n_mean_load</th>\n",
       "      <th>elec</th>\n",
       "      <th>is_dummy</th>\n",
       "      <th>num</th>\n",
       "      <th>year</th>\n",
       "      <th>datetime</th>\n",
       "      <th>padding_dummy</th>\n",
       "      <th>yeartag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.081734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.369594</td>\n",
       "      <td>-1.332963</td>\n",
       "      <td>...</td>\n",
       "      <td>751.32</td>\n",
       "      <td>68.301818</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>99.56</td>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020-12-22 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.081734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449759</td>\n",
       "      <td>-1.321778</td>\n",
       "      <td>...</td>\n",
       "      <td>692.6</td>\n",
       "      <td>62.963636</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>91.78</td>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020-12-22 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.081734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504857</td>\n",
       "      <td>-1.332963</td>\n",
       "      <td>...</td>\n",
       "      <td>597.48</td>\n",
       "      <td>54.316364</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>79.17</td>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020-12-22 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.081734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527416</td>\n",
       "      <td>-1.388888</td>\n",
       "      <td>...</td>\n",
       "      <td>553.48</td>\n",
       "      <td>50.316364</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>73.34</td>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020-12-22 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.081734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513615</td>\n",
       "      <td>-1.388888</td>\n",
       "      <td>...</td>\n",
       "      <td>526.24</td>\n",
       "      <td>47.84</td>\n",
       "      <td>68.606449</td>\n",
       "      <td>69.73</td>\n",
       "      <td>0</td>\n",
       "      <td>4821</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020-12-22 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  district_c0 district_c1 district_c2 district_c3  units_qt    lon_mm lat_mm  \\\n",
       "0         0.0         0.0         0.0         1.0  0.066066  0.081734    0.0   \n",
       "1         0.0         0.0         0.0         1.0  0.066066  0.081734    0.0   \n",
       "2         0.0         0.0         0.0         1.0  0.066066  0.081734    0.0   \n",
       "3         0.0         0.0         0.0         1.0  0.066066  0.081734    0.0   \n",
       "4         0.0         0.0         0.0         1.0  0.066066  0.081734    0.0   \n",
       "\n",
       "  holiday altitude_mm   temp_st  ... sum_load   avg_load n_mean_load   elec  \\\n",
       "0       1    0.369594 -1.332963  ...   751.32  68.301818   68.606449  99.56   \n",
       "1       1    0.449759 -1.321778  ...    692.6  62.963636   68.606449  91.78   \n",
       "2       1    0.504857 -1.332963  ...   597.48  54.316364   68.606449  79.17   \n",
       "3       1    0.527416 -1.388888  ...   553.48  50.316364   68.606449  73.34   \n",
       "4       1    0.513615 -1.388888  ...   526.24      47.84   68.606449  69.73   \n",
       "\n",
       "  is_dummy   num  year             datetime padding_dummy yeartag  \n",
       "0        0  4821  2021  2020-12-22 00:00:00             1     NaN  \n",
       "1        0  4821  2021  2020-12-22 01:00:00             1     NaN  \n",
       "2        0  4821  2021  2020-12-22 02:00:00             1     NaN  \n",
       "3        0  4821  2021  2020-12-22 03:00:00             1     NaN  \n",
       "4        0  4821  2021  2020-12-22 04:00:00             1     NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'num' 열에서 값이 변경되는 위치의 인덱스 찾기\n",
    "change_indices = total_df.index[total_df['num'].shift() != total_df['num']].tolist()\n",
    "change_indices = np.asarray(change_indices, dtype=int)\n",
    "num_order = total_df['num'].iloc[change_indices].values\n",
    "\n",
    "print(len(num_order) == len(total_df['num'].unique()))\n",
    "\n",
    "# Combine all groups into a single DataFrame\n",
    "final_df = pd.concat(result_dict.values()).reset_index(drop=True)\n",
    "\n",
    "# 'num' 열을 num_order 배열의 순서로 정렬하도록 설정\n",
    "final_df['num'] = pd.Categorical(final_df['num'], categories=num_order, ordered=True)\n",
    "\n",
    "# 'num'과 'datetime'을 기준으로 정렬\n",
    "final_df = final_df.sort_values(by=['num', 'datetime']).reset_index(drop=True)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (pre_num == final_df[final_df['padding_dummy'] == 0]['num'].values).all()\n",
    "assert (pre_datetime ==  pd.to_datetime(final_df[final_df['padding_dummy'] == 0]['datetime'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Backup.save_with_key(final_df, f'backup2_{opt}')\n",
    "\n",
    "get_backup = True\n",
    "if get_backup:\n",
    "    final_df = Backup.copy_data_with_key(f'backup2_{opt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207840, 207840, 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = final_df['padding_dummy'].values.astype(int)\n",
    "b = final_df['is_dummy'].values.astype(int)\n",
    "\n",
    "final_df['is_dummy'] = a + b - a * b \n",
    "final_df['is_dummy'] = final_df['is_dummy'].astype(int)\n",
    "\n",
    "np.sum(final_df['is_dummy'] == 1), np.sum(final_df['padding_dummy'] == 1), np.sum(b == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt == 'train':\n",
    "    train_input_df = final_df[input_cols]\n",
    "    train_elec_df = final_df[elec_cols]\n",
    "    train_meta_df = final_df[meta_cols]\n",
    "\n",
    "    train_input_df.to_csv(Path(asset_path, '03_train_input_padding.csv'), index=False)\n",
    "    train_elec_df.to_csv(Path(asset_path, '03_train_elec_padding.csv'), index=False)\n",
    "    train_meta_df.to_csv(Path(asset_path, '03_train_meta_padding.csv'), index=False)\n",
    "\n",
    "else:\n",
    "    test_input_df = final_df[input_cols]\n",
    "    test_meta_df = final_df[meta_cols]\n",
    "\n",
    "    test_input_df.to_csv(Path(asset_path, '03_test_input_padding.csv'), index=False)\n",
    "    test_meta_df.to_csv(Path(asset_path, '03_test_meta_padding.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_TO_DATA:\n",
    "    if opt == 'train':\n",
    "        train_input_df.to_csv(Path(data_path, 'train_input_variables.csv'), index=False)\n",
    "        train_elec_df.to_csv(Path(data_path, 'train_elec_variables.csv'), index=False)\n",
    "        train_meta_df.to_csv(Path(data_path, 'train_meta_information.csv'), index=False)\n",
    "    else:\n",
    "        test_input_df.to_csv(Path(data_path, 'test_input_variables.csv'), index=False)\n",
    "        test_meta_df.to_csv(Path(data_path, 'test_meta_information.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
